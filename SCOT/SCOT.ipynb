{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SCOT"
      ],
      "metadata": {
        "id": "hNQ8GefMYkv6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notebook for SCOT (Semantic Correspondence as an Optimal Transport Problem).\n",
        "\n",
        "References:\n",
        "\n",
        "https://openaccess.thecvf.com/content_CVPR_2020/papers/Liu_Semantic_Correspondence_as_an_Optimal_Transport_Problem_CVPR_2020_paper.pdf\n",
        "\n",
        "https://github.com/csyanbin/SCOT"
      ],
      "metadata": {
        "id": "8gstXNyhYpkC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup and installation"
      ],
      "metadata": {
        "id": "CPxASyGhGEkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JXL1vBE_YeH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Move to SCOT folder under the project root directory."
      ],
      "metadata": {
        "id": "VEGdOubfaRNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/SemesterProj/SCOT/'"
      ],
      "metadata": {
        "id": "WKLVMyyBGbp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install required libraries"
      ],
      "metadata": {
        "id": "LUprYHfAaaPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-image\n",
        "!pip install pandas\n",
        "!pip install requests"
      ],
      "metadata": {
        "id": "jo-QcUAkFsOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "S6x28F2kGILb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports and helper functions"
      ],
      "metadata": {
        "id": "chW1Y6rzadsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.compat import integer_types\n",
        "import argparse\n",
        "import datetime\n",
        "import os\n",
        "import logging\n",
        "import time\n",
        "import cv2\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from model import scot_CAM, geometry, evaluation, util\n",
        "from data import dataset, download\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from itertools import product"
      ],
      "metadata": {
        "id": "yDCYyVn9cauw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class for accesing dict attributes with dot\n",
        "class AttributeDict(dict):\n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__\n",
        "\n",
        "\n",
        "def threshold_img(img_hsv, int_val=False):\n",
        "    \"\"\"\n",
        "    Create a categprical label based on HSV colorspace thresholding.\n",
        "    \"\"\"\n",
        "    # define range of blue color in HSV\n",
        "    lower_blue = np.array([115, 50, 50])\n",
        "    upper_blue = np.array([125, 255, 255])\n",
        "    mask_blue = cv2.inRange(img_hsv, lower_blue, upper_blue)\n",
        "\n",
        "    # define range of green color in HSV\n",
        "    lower_green = np.array([55, 50, 50])\n",
        "    upper_green = np.array([65, 255, 255])\n",
        "    mask_green = cv2.inRange(img_hsv, lower_green, upper_green)\n",
        "\n",
        "    # lower mask (0-10)\n",
        "    lower_red = np.array([0, 50, 50])\n",
        "    upper_red = np.array([5, 255, 255])\n",
        "    mask0_red = cv2.inRange(img_hsv, lower_red, upper_red)\n",
        "\n",
        "    # upper mask (170-180)\n",
        "    lower_red = np.array([175, 50, 50])\n",
        "    upper_red = np.array([180, 255, 255])\n",
        "    mask1_red = cv2.inRange(img_hsv, lower_red, upper_red)\n",
        "\n",
        "    # join my masks\n",
        "    mask_red = mask0_red + mask1_red\n",
        "\n",
        "    if int_val:\n",
        "        # set my output img to zero everywhere except my mask\n",
        "        output_hsv = np.zeros((img_hsv.shape[0], img_hsv.shape[1]))\n",
        "        output_hsv[np.where(mask_red == 255)] = 1\n",
        "        output_hsv[np.where(mask_blue == 255)] = 2\n",
        "        output_hsv[np.where(mask_green == 255)] = 3\n",
        "    else:\n",
        "        output_hsv = np.zeros((img_hsv.shape[0], img_hsv.shape[1], 4))\n",
        "        # Set background one-hot encoding\n",
        "        output_hsv[..., 0] = 1\n",
        "        # Set classes one-hot encoding\n",
        "        output_hsv[np.where(mask_red == 255)] = [0, 1, 0, 0]\n",
        "        output_hsv[np.where(mask_blue == 255)] = [0, 0, 0, 1]\n",
        "        output_hsv[np.where(mask_green == 255)] = [0, 0, 1, 0]\n",
        "\n",
        "    return output_hsv.astype(np.uint8)\n",
        "\n",
        "\n",
        "def search_rect_space(x, y, map_w, map_h, search_w, search_h):\n",
        "    \"\"\"\n",
        "    Define a rectangular search space based on current point and window size.\n",
        "    \"\"\"\n",
        "    # Return top, left, right, bottom coordinates of a patch centered in x,y\n",
        "    search_min_r = max(x - search_h // 2, 0)\n",
        "    search_max_r = min(x + search_h // 2, map_h)\n",
        "    search_min_c = max(y - search_w // 2, 0)\n",
        "    search_max_c = min(y + search_w // 2, map_w)\n",
        "\n",
        "    r_range = list(range(search_min_r, search_max_r))\n",
        "    c_range = list(range(search_min_c, search_max_c))\n",
        "\n",
        "    return list(product(r_range, c_range))\n",
        "\n",
        "\n",
        "def change_label_to_onehot(label, new_h, new_w):\n",
        "    label_int = np.zeros((new_h, new_w, 4), dtype=np.uint8)\n",
        "    label_int[..., 0] = 1\n",
        "    label_int[np.where(label == 1)] = [0, 1, 0, 0]\n",
        "    label_int[np.where(label == 2)] = [0, 0, 1, 0]\n",
        "    label_int[np.where(label == 3)] = [0, 0, 0, 1]\n",
        "\n",
        "    return label_int"
      ],
      "metadata": {
        "id": "-6Q4LgLLxQal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference\n"
      ],
      "metadata": {
        "id": "WfUmGBVHbMtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run(datapath, ann_dir, img_dir, drone_dir, benchmark, backbone, thres, alpha, hyperpixel,\n",
        "        logpath, args, beamsearch=False, model=None, dataloader=None,\n",
        "        weight_type='average_channel', output_path='./', side_thres=300, show=False,\n",
        "        interp='nn', search_dim_w='50'):\n",
        "    \n",
        "    \"\"\"Runs Semantic Correspondence as an Optimal Transport Problem\"\"\"\n",
        "\n",
        "    # Create output_path if does not exists\n",
        "    output_path = os.path.expanduser(output_path)\n",
        "    os.makedirs(output_path, mode=0o777, exist_ok=True)\n",
        "\n",
        "    # Evaluation benchmark initialization\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    if dataloader is None:\n",
        "        if benchmark != 'drone':\n",
        "            download.download_dataset(os.path.abspath(datapath), benchmark)\n",
        "        split = args.split\n",
        "        dset = download.load_dataset(benchmark, datapath, thres, device, split, args.cam, ann_dir, img_dir, drone_dir)\n",
        "        dataloader = DataLoader(dset, batch_size=1, num_workers=0)\n",
        "\n",
        "    # Model initialization\n",
        "    if model is None:\n",
        "        model = scot_CAM.SCOT_CAM(backbone, hyperpixel, benchmark, device, args.cam)\n",
        "    else:\n",
        "        model.hyperpixel_ids = util.parse_hyperpixel(hyperpixel)\n",
        "\n",
        "    for idx, data in enumerate(dataloader):\n",
        "        # Retrieve images and adjust their sizes to avoid large numbers of hyperpixels\n",
        "        data['src_img'], data['src_kps'], data['src_intratio'] = util.resize(data['src_img'], data['src_kps'][0], side_thres=side_thres)\n",
        "        data['trg_img'], data['trg_kps'], data['trg_intratio'] = util.resize(data['trg_img'], data['trg_kps'][0], side_thres=side_thres)\n",
        "        src_size = data['src_img'].size()\n",
        "        trg_size = data['trg_img'].size()\n",
        "        data['src_mask'] = None\n",
        "        data['trg_mask'] = None\n",
        "        data['alpha'] = alpha\n",
        "\n",
        "        # Feed a pair of images to Hyperpixel Flow model\n",
        "        with torch.no_grad():\n",
        "            # Confidence matrix size is img_size / 4\n",
        "            confidence_ts, src_box, trg_box, hyper_h, hyper_w = model(data['src_img'], data['trg_img'], args.sim, args.exp1, args.exp2, args.eps, args.classmap, data['src_bbox'], data['trg_bbox'], data['src_mask'], data['trg_mask'], backbone)\n",
        "            \n",
        "            # Read satellite label and transform according to interpolation method\n",
        "            if interp == 'nn':\n",
        "                label = Image.open(os.path.join(dset.label_img_path, data['label_imname'][0]))\n",
        "                orig_h, orig_w = label.size[1], label.size[0]\n",
        "                label = np.array(label.resize((hyper_w, hyper_h), Image.NEAREST))\n",
        "                label_int = change_label_to_onehot(label, hyper_h, hyper_w)\n",
        "            else:\n",
        "                label = np.array(Image.open(os.path.join(dset.label_img_path, data['label_imname'][0])).convert(\"RGB\"))[:, :, ::-1]\n",
        "                orig_h, orig_w = label.shape[0], label.shape[1]\n",
        "                label = cv2.resize(label, (hyper_w, hyper_h), interpolation=cv2.INTER_AREA)\n",
        "                label_hsv = cv2.cvtColor(label, cv2.COLOR_BGR2HSV)\n",
        "                label_int = threshold_img(label_hsv)\n",
        "\n",
        "            # Reshape label\n",
        "            label_h, label_w = label_int.shape[0], label_int.shape[1]\n",
        "            old_label = label_int.reshape((label_h * label_w, 4))\n",
        "\n",
        "            # Build map of 2d indexes to 1d indexes for confidence matrix\n",
        "            map_two_one = {}\n",
        "            for i in range(confidence_ts.size()[0]):\n",
        "                map_two_one[(i // label_w, i % label_w)] = i\n",
        "\n",
        "            # Define windows size for filtered search space in confidence matrix\n",
        "            if 'filtered' in weight_type:\n",
        "                size_ratio = label_w / label_h\n",
        "                search_w = search_dim_w\n",
        "                search_h = int(search_w / size_ratio)\n",
        "\n",
        "            # Create warped image by averaging\n",
        "            if 'average' in weight_type:\n",
        "                if 'average_filtered' in weight_type:\n",
        "                    confidence_ts = confidence_ts.detach().cpu().numpy()\n",
        "                    weighted_label = np.zeros((confidence_ts.shape[0], old_label.shape[1]))\n",
        "\n",
        "                    for i in range(label_h):\n",
        "                        for j in range(label_w):\n",
        "                            # Define list of points to be searched and transform to 1d coordinates\n",
        "                            search_points_2d = search_rect_space(i, j, map_w=label_w, map_h=label_h, search_w=search_w, search_h=search_h)\n",
        "                            points_1d_coord = [map_two_one[p] for p in search_points_2d]\n",
        "\n",
        "                            # Normalize confidence map row of interested points, to sum to 1\n",
        "                            coef_conf = 1 / (confidence_ts[map_two_one[(i, j)], points_1d_coord].sum())\n",
        "                            row_confidence_ts = (coef_conf * confidence_ts[map_two_one[(i, j)], points_1d_coord])\n",
        "                            # Compute new weighted label\n",
        "                            weighted_label[map_two_one[(i, j)]] = np.dot(row_confidence_ts[np.newaxis, ...], old_label[points_1d_coord, :])\n",
        "\n",
        "                else:\n",
        "                    # Normalize confidence map rows, to sum to 1\n",
        "                    coef_conf = 1 / confidence_ts.sum(1, keepdim=True)\n",
        "                    confidence_ts = (coef_conf * confidence_ts).detach().cpu().numpy()\n",
        "                    # Compute new weighted label\n",
        "                    weighted_label = np.dot(confidence_ts, old_label)\n",
        "\n",
        "                # Take the maximum \n",
        "                new_label = np.argmax(weighted_label, axis=1).reshape((label_int.shape[0], label_int.shape[1]))\n",
        "\n",
        "                # Change drone label format\n",
        "                drone_label = change_label_to_onehot(new_label, new_label.shape[0], new_label.shape[1])\n",
        "\n",
        "            # Create warped image by taking the maximum\n",
        "            elif 'max' in weight_type:\n",
        "                if 'max_filtered' in weight_type:\n",
        "                    confidence_ts = confidence_ts.detach().cpu().numpy()\n",
        "                    drone_label = np.zeros_like(label_int)\n",
        "\n",
        "                    for i in range(label_h):\n",
        "                        for j in range(label_w):\n",
        "                            # Define list of points to be searched and transform to 1d coordinates\n",
        "                            search_points_2d = search_rect_space(i, j, map_w=label_w, map_h=label_h, search_w=search_w, search_h=search_h)\n",
        "                            points_1d_coord = [map_two_one[p] for p in search_points_2d]\n",
        "\n",
        "                            # Take the maximum from possible points and compute the new label\n",
        "                            trg_idx = np.argsort(confidence_ts[map_two_one[(i, j)], points_1d_coord])[::-1][0]\n",
        "                            trg_idx = points_1d_coord[trg_idx]\n",
        "                            drone_label[i, j] = label_int[trg_idx // label_w, trg_idx % label_w]\n",
        "\n",
        "                else:\n",
        "                    # Take the maximum and compute new label\n",
        "                    conf, trg_indices = torch.max(confidence_ts, dim=1)\n",
        "                    trg_indices = trg_indices.detach().cpu().numpy()\n",
        "                    drone_label = np.zeros_like(label_int)\n",
        "                    for i, index in enumerate(trg_indices):\n",
        "                        y_coord_drone = i % label_w\n",
        "                        x_coord_drone = i // label_w\n",
        "                        y_coord_sat = index % label_w\n",
        "                        x_coord_sat = index // label_w\n",
        "                        drone_label[x_coord_drone, y_coord_drone] = label_int[x_coord_sat, y_coord_sat]\n",
        "\n",
        "            drone_label = drone_label.astype(np.uint8)\n",
        "\n",
        "            # Resize back to original size according to interpolation method\n",
        "            if interp == 'nn':\n",
        "                drone_label_int = np.zeros((drone_label.shape[0], drone_label.shape[1]))\n",
        "                drone_label_int[np.where(drone_label[..., 1] == 1)] = 1\n",
        "                drone_label_int[np.where(drone_label[..., 2] == 1)] = 2\n",
        "                drone_label_int[np.where(drone_label[..., 3] == 1)] = 3\n",
        "                drone_label = Image.fromarray(drone_label_int.astype(np.uint8))\n",
        "                output_label = np.array(drone_label.resize((orig_w, orig_h), Image.NEAREST))\n",
        "            else:\n",
        "                drone_label_rgb = np.zeros((drone_label.shape[0], drone_label.shape[1], 3))\n",
        "                drone_label_rgb[np.where(drone_label[..., 1] == 1)] = [255, 0, 0]\n",
        "                drone_label_rgb[np.where(drone_label[..., 2] == 1)] = [0, 255, 0]\n",
        "                drone_label_rgb[np.where(drone_label[..., 3] == 1)] = [0, 0, 255]\n",
        "                drone_label_rgb = drone_label_rgb.astype(np.uint8)\n",
        "\n",
        "                drone_label = cv2.resize(drone_label_rgb, (orig_w, orig_h), interpolation=cv2.INTER_CUBIC)\n",
        "                drone_label = drone_label[:, :, ::-1]\n",
        "                drone_label_hsv = cv2.cvtColor(drone_label, cv2.COLOR_BGR2HSV)\n",
        "                output_label = threshold_img(drone_label_hsv, int_val=True)\n",
        "            \n",
        "            # Convert warped label to 'P' mode, put palette and save\n",
        "            seg_img = Image.fromarray(output_label).convert('P')\n",
        "            seg_img.putpalette(np.array([[0, 0, 0], [255, 0, 0], [0, 0, 255], [0, 255, 0]], dtype=np.uint8))\n",
        "            seg_img.save(os.path.join(output_path, data['label_imname'][0]))\n",
        "\n",
        "            if show:\n",
        "                label =  np.array(Image.open(os.path.join(output_path, data['label_imname'][0])).convert(\"RGB\"))\n",
        "                drone_img =  np.array(Image.open(os.path.join(dset.src_img_path, data['label_imname'][0].split('.')[0] + '.jpg')))\n",
        "                overlay = cv2.addWeighted(drone_img, 0.6, label, 0.7, 0)\n",
        "                plt.imshow(overlay)\n",
        "\n",
        "        print(\"IDX is {}\".format(idx))\n"
      ],
      "metadata": {
        "id": "EF6MZX7RbuN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuration and running"
      ],
      "metadata": {
        "id": "mO1W52KHb8Tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set configuration dictionary\n",
        "\n",
        "args = {# GPU id\n",
        "        'gpu': '0',\n",
        "        # Dataset path\n",
        "        'datapath': '../data/120m/',\n",
        "        # Satellite labels directory\n",
        "        'ann_dir': 'ann_dir',\n",
        "        # Satellite images directory\n",
        "        'img_dir': 'img_dir',\n",
        "        # Drone images directory\n",
        "        'drone_dir': 'drone_dir',\n",
        "        # Split to use: 'train' or 'test' - sequentially given for full dataset generation\n",
        "        'split': 'test',\n",
        "        # Dataset type\n",
        "        'dataset': 'drone',\n",
        "        # Backbone type\n",
        "        'backbone': 'resnet101',\n",
        "        # Thresholding type\n",
        "        'thres': 'img',\n",
        "        'alpha': 0.05,\n",
        "        'hyperpixel': '(2,4,5,18,19,20,24,32)',\n",
        "        'logpath': '',\n",
        "        # Similarity type: OT, cos, OTGeo, cosGeo (the last 2 use RHM)\n",
        "        'sim': 'OTGeo',\n",
        "        # Exponential factor on initial cosine cost (default)\n",
        "        'exp1': 1.0,\n",
        "        # Exponential factor on final OT scores (default)\n",
        "        'exp2': 0.5,\n",
        "        # Epsilon for Sinkhorn Regularization (default)\n",
        "        'eps': 0.05,\n",
        "        # Whether to use(1) classmap or not(0) - we skip classmap here\n",
        "        'classmap': 0,\n",
        "        # Activation map folder, empty for end2end computation\n",
        "        'cam': '',\n",
        "        # Method to compute warped satellite labels: 'max', 'max_filtered', 'average' or 'average_filtered'\n",
        "        'weight_type': 'max',\n",
        "        # Target size of the biggest image side when used for training\n",
        "        'side_thres': 480,\n",
        "        # Output path for warped images\n",
        "        'output_path': '',\n",
        "        # Interpolation type when resizing: 'nn' or 'threshold_csv'\n",
        "        'interp': 'threshold_csv',\n",
        "        # If any 'filtered' method is used for 'weight_type', this is the window size for the search space,\n",
        "        # when constraining the reconstruction\n",
        "        'search_dim_w': 50}\n",
        "\n",
        "args = AttributeDict(args)\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
        "args.output_path = os.path.join(args.datapath, 'scot_warped_{}_{}'.format(args.side_thres, args.weight_type))\n",
        "\n",
        "# Call SCOT function\n",
        "run(datapath=args.datapath, ann_dir=args.ann_dir, img_dir=args.img_dir,\n",
        "    drone_dir=args.drone_dir, benchmark=args.dataset, backbone=args.backbone,\n",
        "    thres=args.thres, alpha=args.alpha, hyperpixel=args.hyperpixel,\n",
        "    logpath=args.logpath, args=args, beamsearch=False, weight_type=args.weight_type, \n",
        "    output_path=args.output_path, side_thres=args.side_thres, show=True,\n",
        "    interp=args.interp, search_dim_w=args.search_dim_w)"
      ],
      "metadata": {
        "id": "ffCuYP5MbNgw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}